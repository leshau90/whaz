{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c districtdatalabs yellowbrick\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from ydata_profiling import ProfileReport\n",
    "import sklearn\n",
    "# sklearn.set_config(transform_output=\"pandas\")\n",
    "# import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labeller  =  preprocessing.LabelEncoder()\n",
    "ohe = preprocessing.OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_items = pd.read_csv('./dataset/olist_order_items_dataset.csv')\n",
    "customers = pd.read_csv('./dataset/olist_customers_dataset.csv')\n",
    "sellers = pd.read_csv('./dataset/olist_sellers_dataset.csv')\n",
    "products = pd.read_csv('./dataset/olist_products_dataset.csv')\n",
    "orders = pd.read_csv('./dataset/olist_orders_dataset.csv')\n",
    "reviews = pd.read_csv('./dataset/olist_order_reviews_dataset.csv')\n",
    "geos = pd.read_csv('./dataset/olist_geolocation_dataset.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders.info()\n",
    "# order_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orders[['order_purchase_timestamp',\n",
    "        'order_approved_at',\n",
    "        'order_delivered_carrier_date',\n",
    "        'order_delivered_customer_date',\n",
    "        'order_estimated_delivery_date']] = orders[['order_purchase_timestamp',\n",
    "                                                    'order_approved_at',\n",
    "                                                    'order_delivered_carrier_date',\n",
    "                                                    'order_delivered_customer_date',\n",
    "                                                    'order_estimated_delivery_date']].apply(pd.to_datetime) \n",
    "reviews[['review_creation_date',\n",
    "        'review_answer_timestamp']] = reviews[['review_creation_date',\n",
    "                                                    'review_answer_timestamp']].apply(pd.to_datetime) \n",
    "order_items[['shipping_limit_date']] = order_items[['shipping_limit_date']].apply(pd.to_datetime)\n",
    "# order_items.info(),orders.info()\n",
    "# order_items.head()\n",
    "# customers.head(),order_items.head(),orders.head(),customers[customers['customer_id'] == \"9ef432eb6251297304e76186b10a928d\"], customers[customers['customer_unique_id'] == \"9ef432eb6251297304e76186b10a928d\"]\n",
    "# ProfileReport(order_items,title=\"order of items\").to_widgets()\n",
    "\n",
    "# orders.info()\n",
    "merged = orders.merge(order_items, how='inner')\n",
    "\n",
    "merged = merged.merge(customers)\n",
    "# merged.info()\n",
    "merged = merged.merge(sellers)\n",
    "merged = merged.merge(products)\n",
    "merged = merged.merge(reviews)\n",
    "\n",
    "\n",
    "merged['product_photos_qty']=merged['product_photos_qty'].fillna(0)\n",
    "# merged[merged['product_photos_qty'].isna()][['customer_id','product_photos_qty']]\n",
    "\n",
    "# merged[['seller_city','seller_state','customer_city','customer_state']] = merged[['seller_city','seller_state','customer_city','customer_state']].astype('category') \n",
    "# merged[['seller_city','seller_state','customer_city','customer_state']].info()\n",
    "# print(merged[['seller_city','seller_state','customer_city','customer_state','review_score']].head())\n",
    "# print(merged['customer_city'].value_counts())\n",
    "# merged['seller_city'] = labeller.fit_transform(merged['seller_city'].astype('str'))\n",
    "# merged['seller_state'] = labeller.fit_transform(merged['seller_state'].astype('str'))\n",
    "# merged['customer_city'] = labeller.fit_transform(merged['customer_city'].astype('str'))\n",
    "# merged['customer_state'] = labeller.fit_transform(merged['customer_state'].astype('str'))\n",
    "merged['review_score'] = labeller.fit_transform(merged['review_score'].astype('str'))\n",
    "\n",
    "# print(merged[['seller_city','seller_state','customer_city','customer_state','review_score']].head())\n",
    "# merged[['seller_city','seller_state','customer_city','customer_state','review_score']].info()\n",
    "\n",
    "\n",
    "merged['time_to_get'] = merged.order_delivered_customer_date - merged['order_purchase_timestamp']\n",
    "merged['time_to_get'] = merged['time_to_get'].dt.seconds/(60*60)\n",
    "merged['time_to_get'] = merged['time_to_get']\n",
    "\n",
    "merged.sort_values(by='order_purchase_timestamp',inplace=True)\n",
    "# merged['time_to_get'] = merged['time_to_get'].replace(np.nan, 0)\n",
    "# merged.time_to_get.isna().sum()\n",
    "merged.dropna(subset=['price'],inplace=True)\n",
    "# print(merged.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merged[['price']].hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.hist(figsize=(15,15),xlabelsize=7,ylabelsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding on the seller city and customer city\n",
    "tohe = ohe.fit_transform(merged[['seller_city']])\n",
    "one_hot = pd.get_dummies(merged['seller_city'], prefix='seller_from')\n",
    "merged = pd.concat([merged, one_hot], axis=1)\n",
    "\n",
    "\n",
    "tohe = ohe.fit_transform(merged[['customer_city']])\n",
    "one_hot2 = pd.get_dummies(merged['customer_city'], prefix='customer_from')\n",
    "merged = pd.concat([merged, one_hot2], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ohc = list(one_hot.columns)+list(one_hot2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.dropna(subset=['order_approved_at', 'product_length_cm', 'product_height_cm', 'product_width_cm',\n",
    "                      'order_delivered_carrier_date', 'order_delivered_customer_date', 'product_category_name',\n",
    "       'product_name_lenght', 'product_description_lenght','time_to_get'],inplace=True)\n",
    "merged.fillna(value={'review_comment_title':'no comment', 'review_comment_message':'no_comment'},inplace=True)\n",
    "\n",
    "\n",
    "# print(merged.info())\n",
    "# print(len(merged.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without further preprocessing\n",
    "merged['seller_city'] = labeller.fit_transform(merged['seller_city'].astype('str'))\n",
    "merged['seller_state'] = labeller.fit_transform(merged['seller_state'].astype('str'))\n",
    "merged['customer_city'] = labeller.fit_transform(merged['customer_city'].astype('str'))\n",
    "merged['customer_state'] = labeller.fit_transform(merged['customer_state'].astype('str'))\n",
    "\n",
    "X = merged[['price','freight_value','seller_city','seller_state'\n",
    "            ,'customer_city','customer_state','time_to_get']]\n",
    "# merged['review_score_transformed'] = merged['review_score']-1\n",
    "\n",
    "# first we are goin to map seller_city and seller_satate and its customer conterpart to  unique integer,later we are also going to test one hot encoding\n",
    "y = merged['review_score']\n",
    "\n",
    "\n",
    "# sns.heatmap(X.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#train the simple decision tree model\n",
    "time_check = {\"dtc\":0,\"xgb\":0,\"rf\":0}\n",
    "s = time()\n",
    "dtc_model = tree.DecisionTreeClassifier()\n",
    "dtc_model.fit(X_train, y_train)\n",
    "time_check['dtc'] = time() - s\n",
    "dtc_pred = dtc_model.predict(X_test)\n",
    "dtc_report = classification_report(y_test, dtc_pred)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(dtc_report)\n",
    "print(\"for(s):\", time_check['dtc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "time_check['xgb'] = time() - s\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_report = classification_report(y_test, xgb_pred)\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(xgb_report)\n",
    "print(\"for(s):\", time_check['xgb'])\n",
    "\n",
    "# Train the Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time()\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "time_check['rf'] = time() - s\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_report = classification_report(y_test, rf_pred)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(rf_report)\n",
    "print(\"for(s):\", time_check[\"rf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "s = time()\n",
    "knn_model = KNeighborsClassifier(5,weights='uniform')\n",
    "knn_model.fit(X_train, y_train)\n",
    "time_check['knn'] = time() - s\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_report = classification_report(y_test, knn_pred)\n",
    "print(\"k-NN Classification Report:\")\n",
    "print(knn_report)\n",
    "print(\"for(s):\", time_check[\"knn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# fg, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "                                              y_test, \n",
    "                                              xgb_pred, \n",
    "                                            #   display_labels=labels, \n",
    "                                              cmap=plt.cm.Blues\n",
    "                                              ) \n",
    "fig = disp.figure_\n",
    "fig.set_figwidth(5)\n",
    "fig.set_figheight(5) \n",
    "fig.suptitle('XGB')\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "                                              y_test, \n",
    "                                              rf_pred, \n",
    "                                            #   display_labels=labels, \n",
    "                                              cmap=plt.cm.Blues\n",
    "                                              ) \n",
    "fig2 = disp.figure_\n",
    "fig2.set_figwidth(5)\n",
    "fig2.set_figheight(5) \n",
    "fig2.suptitle('Random Forest')\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "                                              y_test, \n",
    "                                              dtc_pred, \n",
    "                                            #   display_labels=labels, \n",
    "                                              cmap=plt.cm.Blues\n",
    "                                              ) \n",
    "fig2 = disp.figure_\n",
    "fig2.set_figwidth(5)\n",
    "fig2.set_figheight(5) \n",
    "fig2.suptitle('Decision Tree')\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "                                              y_test, \n",
    "                                              knn_pred, \n",
    "                                            #   display_labels=labels, \n",
    "                                              cmap=plt.cm.Blues\n",
    "                                              ) \n",
    "fig2 = disp.figure_\n",
    "fig2.set_figwidth(5)\n",
    "fig2.set_figheight(5) \n",
    "fig2.suptitle('K-NN(5,uniform)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
